# Sistema de ClasificaciÃ³n de GÃ©nero por Voz usando Deep Learning ðŸŽ¤

![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.7+-red.svg)
![Librosa](https://img.shields.io/badge/Librosa-0.8+-green.svg)

Sistema de clasificaciÃ³n automÃ¡tica del gÃ©nero del hablante utilizando caracterÃ­sticas acÃºsticas y redes neuronales convolucionales. Este proyecto forma parte de una tesis de maestrÃ­a que explora diferentes tÃ©cnicas de procesamiento de seÃ±ales de audio y aprendizaje profundo.

## ðŸ” Palabras Clave

`reconocimiento-de-voz` `deep-learning` `procesamiento-de-audio` `clasificacion-de-genero` `pytorch` `cnn` `redes-neuronales` `espectrogramas` `mfcc` `mel-spectrograms` `voxceleb` `procesamiento-de-seÃ±ales` `machine-learning` `python` `librosa` `audio-processing` `gender-recognition` `voice-processing` `tesis` `audio-features` `speaker-recognition`

## ðŸš€ CaracterÃ­sticas Principales

- Procesamiento avanzado de seÃ±ales de audio
- ExtracciÃ³n de mÃºltiples caracterÃ­sticas acÃºsticas:
  - Espectrogramas
  - Espectrogramas Mel
  - Coeficientes MFCC
- Modelo CNN personalizado para clasificaciÃ³n
- Pipeline completo de preprocesamiento y entrenamiento
- Soporte para el dataset VoxCeleb

## ðŸ“Š Estructura del Proyecto

```
â”œâ”€â”€ audio preprocessing/     # Preprocesamiento de seÃ±ales de audio
â”œâ”€â”€ dataset/                # Manejo y organizaciÃ³n del dataset
â”œâ”€â”€ extract features/       # ExtracciÃ³n de caracterÃ­sticas
â”œâ”€â”€ train test/            # Entrenamiento y evaluaciÃ³n
â””â”€â”€ docs/                  # DocumentaciÃ³n
```

## ðŸ› ï¸ CaracterÃ­sticas TÃ©cnicas

### Procesamiento de Audio
- Frecuencia de muestreo: 16kHz
- Ventana FFT: 1024 muestras
- Ventana de anÃ¡lisis: Hann
- Hop length: 160 muestras
- Bandas Mel: 224

### Arquitectura CNN
- Capa convolucional (1->16 canales)
- ReLU
- MaxPooling
- Fully connected (16*32*32 -> 128)
- Fully connected (128 -> num_classes)

## ðŸ”§ Requisitos

```
python >= 3.7
torch >= 1.7
librosa >= 0.8
numpy
pandas
matplotlib
pillow
tqdm
```

## ðŸ“¥ InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone https://github.com/tu-usuario/tesis.git
cd tesis
```

2. Instalar dependencias:
```bash
pip install -r requirements.txt
```

## ðŸš¦ Uso
-Se puede aplicar a aplicaciones en dispositivos de bajo rendimiento computacional, ya que ejecutas modelos como Mobilnet.

### Preprocesamiento de Audio
```bash
python audio_preprocessing/procesamiento_audio.py
```

### ExtracciÃ³n de CaracterÃ­sticas
```bash
python extract_features/Guardar_MelSpectograma.py
python extract_features/Guardar_MFCC.py
python extract_features/Guardar_Spectograma.py
```

### Entrenamiento del Modelo
```bash
python train_test/cnn_pytorch.py
```

## ðŸ“Š Estructura del Dataset

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ male/    # ~56,000 muestras
â”‚   â””â”€â”€ female/  # ~56,000 muestras
â””â”€â”€ test/
    â”œâ”€â”€ male/    # ~5,500 muestras
    â””â”€â”€ female/  # ~5,500 muestras
```

## ðŸ“ˆ Resultados

- Dataset: VoxCeleb
- Muestras totales: ~123,000
- DivisiÃ³n: 90% entrenamiento, 10% prueba
- Balanceado por gÃ©nero
- Accuracy: 98.95%

## ðŸ‘¥ Autores

- MSc. Jorge Luis Jorrin
- Asesores:
  - Dra. Mariko Nakano

## ðŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia GNU GENERAL PUBLIC LICENSE - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ðŸ”— Referencias

- [VoxCeleb Dataset](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/)
- Enlaces a papers relevantes
